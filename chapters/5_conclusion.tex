\chapter{Conclusion}
\label{sec:conclusion}

We have presented a study of sample generation and correction strategies for training FNNs to learn heuristic functions for classical planning. We have revised existing approaches to sample generation and proposed a new strategy that uses regression with BFS and random walks and several techniques that improve cost-to-goal estimates. By revising and refining existing sample generation methods, we have successfully enhanced the overall performance of the learned heuristic functions, achieving nearly double the coverage compared to our baseline.

Among our contributions, the cost-to-goal improvement technique SUI and the adaptive regression limit \meanfx have the most positive effects on sampling quality. The former improves the accuracy of cost-to-goal estimates by analyzing the successors of a state, while the latter avoids overestimates by limiting the maximum regression limit so that we have a sampling distribution within a reasonable cost-to-goal range. Also, one of our main findings is that having fewer samples with more accurate \h-values is better than having more samples with inaccurate \h-values. Furthermore, having multiple random walk rollouts -- especially when combined with BFS~-- generates samples with better quality when compared to using only BFS or DFS.

Finally, a systematic analysis of small state spaces against ideal baselines seems to indicate that: a)~for the samples obtained through regression, a distribution covering various portions of the state space without repeated samples close to the goal works best, b)~both the sample size and reasonable cost-to-goal estimates contribute to search performance, with the latter being more important, c)~enough samples of good quality translate to good search performance that can be compared to traditional heuristics, although logic-independent approaches (e.g.,~without mutexes) are currently not as good as logic-dependent ones.

Future works can be conducted to investigate the scalability of the proposed techniques, as well as approaches that address the limitations described in \cref{sec:limitations} can be explored. Additionally, compared to traditional heuristics, some domains have poor results with learned heuristics, such as Rovers, which, as far as we know, has a low coverage among all NN-based methods. It needs to be clarified why some domains perform well and others poorly among different learned heuristics.

We validate the findings of \citet{otoole2022sampling} that including randomly generated samples in the sample set has a consistently positive influence. However, the underlying reasons for this effect remain unexplained. A study on random sampling can be conducted to understand its effect when combined with other sampling methods. Still, exploring new approaches to determine the cost-to-goal estimate in random samples as an alternative to the current arbitrary value could improve performance.

Furthermore, sampling approaches involving novelty can be promising. \citet{otoole2022sampling} proposed generating states that maximize the number of undiscovered facts, i.e., facts that have not been observed in any state of the current rollout, during the random walk steps. While their approach does not yield significant gains, other novelty or information gain methods can be explored.

Finally, heuristic functions with logic-independent approaches seem promising. The experiments demonstrate competitive results compared to the mutex-based one, with a coverage difference of less than $4\,\%$ in 8 out of 10 domains addressed. These findings indicate the potential of logic-independent approaches, such as those with black-box interfaces.
