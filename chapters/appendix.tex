\appendix

\chapter{Resumo Expandido}
\label{sec:resumo_expandido}

O planejamento clássico oferece uma abordagem para representar e resolver uma variedade de problemas. Ao formular esses problemas como tarefas de planejamento, é possível modelar desafios reais, como planejamento de rotas, robótica, verificação de sistemas automatizados, e biologia computacional~\cite{edelkamp2012heuristic}. Essa abordagem permite que sistemas automatizados raciocinem, tomem decisões e gerem planos para alcançar objetivos específicos.

Existem diversas abordagens para encontrar uma sequência de ações que transforme um estado inicial em um estado que satisfaça a condição objetivo. Uma estratégia bem-sucedida para resolver essas tarefas é usar algoritmos de \textit{best-first search}, os quais são guiados por uma função heurística que estima o custo para alcançar uma solução a partir de um dado estado. Em geral, esses algoritmos são mais eficazes quando a função heurística estima de forma mais precisa o custo ideal~\hstar para alcançar o objetivo.

O interesse em aprender funções heurísticas com redes neurais~\cite{yu2020learning,shen2020learning,ferber2020neural,toyer2020asnets,ferber2022neural,otoole2022sampling} tem crescido devido ao rápido progresso em outras áreas de aplicação. A abordagem básica é simples: gera-se um conjunto de amostras composto de pares de estados e estimadores de custo-para-o-objetivo, e, em seguida, um modelo supervisionado é treinado usando esse conjunto de amostras. Com o intuito de aprimorar a qualidade das funções heurísticas aprendidas, nosso objetivo é investigar sistematicamente os métodos de geração de amostras para entender a influência de cada técnica no desempenho das estratégias de amostragem e propor novas abordagens que melhorem esse processo.

Para gerar nosso conjunto de amostras, expandimos o espaço de estados \textit{backward} via regressão a partir do estado objetivo. Nós aplicamos os algoritmos de busca em largura~(BFS), busca em profundidade~(DFS), e \textit{random walk}. Todo estado expandido é amostrado juntamente com a distância percorrida até alcançá-lo, que representa seu estimador de custo-para-o-objetivo. Buscando aproveitar as vantagens de cada algoritmo de amostragem, apresentamos uma nova combinação de BFS e \textit{random walk}, chamada \textit{Focused Sampling Method} (FSM). O FSM realiza a amostragem em duas etapas: primeiro, uma porcentagem fixa do total desejado de amostras é gerada usando BFS. Em seguida, são realizados \textit{random walks} sequenciais a partir dos nós folha do BFS até atingir o número total de amostras. Cada um desses \textit{random walks} é chamado de \textit{rollout} e é interrompido ao atingir um limite máximo de regressão.

O limite de regressão serve a dois objetivos principais. Primeiro, especialmente em métodos baseados em regressão, ele ajuda a manter a precisão do estimador de custo-para-o-objetivo, que tende a degradar durante a amostragem devido à natureza aleatória de algoritmos como \textit{random walk} ou DFS. Em segundo lugar, ele regula a distribuição das amostras ao reiniciar periodicamente a amostragem, distribuindo-as efetivamente em diferentes distâncias do objetivo.

Como alternativa aos limites fixos usados em trabalhos anteriores, nós propomos dois métodos adaptativos para definir um limite máximo adequado de regressão com base nos parâmetros da tarefa. O primeiro método usa o número de fatos~$F = |\mathcal{F}(s_0)|$ como estimativa aproximada do número de passos necessários para alcançar o estado mais distante do objetivo. O segundo, mais refinado, usa também o número médio de efeitos dos operadores e é denotado por $\bar F=\ceil{\facts/\overline{\eff}}$ onde $\overline{\eff}=\sum_{o\in \mathcal{O}} |\eff(o)|/|\mathcal{O}|$.

Além da seleção do conjunto de estados, a qualidade das amostras também é influenciada pelos estimadores de custo-para-o-objetivo. Em nossa abordagem, onde os estimadores recebem valor igual ao número de passos da regressão, o valor sempre é igual ou superior a~\hstar. Assim, buscando aprimorar a qualidade do conjunto de amostras, nós propomos duas técnicas para aproximar os estimadores de custo-para-o-objetivo do custo ideal~\hstar.

Ao gerar amostras por múltiplos \textit{rollouts}, um mesmo estado pode ser amostrado diferentes vezes com diferentes estimadores. Essa variação nos valores de custo-para-o-objetivo para um mesmo estado pode causar inconsistências e afetar o aprendizado durante o treinamento da rede neural. Para lidar com esse problema, nós propomos o \textit{Sample Improvement}~(SAI). O SAI seleciona um único estimador de custo-para-o-objetivo para cada estado único, optando sempre pelo valor mais baixo entre todas as amostras do estado em específico.

Além de amostrar um mesmo estado em diferentes \textit{rollouts}, é comum amostrar estados vizinhos no espaço de estados. Ao amostrar estados vizinhos, podemos usar informações locais para aumentar a precisão dos estimadores de custo-para-o-objetivo. Para isso, propomos o \textit{Successor Improvement}~(SUI). O SUI usa o fato de que amostras vizinhas, distantes por um operador, podem ser conectadas por esse operador para formar um novo caminho até o objetivo e, consequentemente, novos estimadores de custo-para-o-objetivo. Podemos atualizar o estimador de custo-para-o-objetivo correspondente para aproximar-se de \hstar se ele produzir um caminho mais curto do que o caminho atual. Ambas as técnicas de melhoria dos estimadores de custo-para-o-objetivo são aplicadas após a amostragem.

Então, usamos uma rede neural residual~\cite{he2016deep} para aprender uma função heurística treinada sobre nosso conjunto de amostras e específica para um espaço de estados. A entrada da rede consiste em uma representação booleana do estado, onde um fato é definido como~$1$ se for verdadeiro no estado e~$0$ caso contrário. A saída é um único neurônio com o valor \h predito. A estrutura da rede inclui duas camadas ocultas, seguidas por um bloco residual com mais duas camadas ocultas. Cada camada oculta contém $250$~neurônios que usam a função de ativação ReLU.

Os experimentos são divididos em dois conjuntos. No primeiro, analisamos o desempenho das diferentes técnicas de amostragem nas tarefas de planejamento em que é possível enumerar o espaço de estados completo com \hstar. Neste contexto, estudamos como diferentes métodos podem influenciar o número de estados expandidos na busca por uma solução. No segundo conjunto, avaliamos a generalização de nossas descobertas para configurações práticas com tarefas de planejamento maiores. Além disso, comparamos nossos métodos com heurísticas tradicionais e trabalhos anteriores.

Uma análise sistemática em comparação com baselines ideais parece indicar que: a)~para as amostras obtidas por regressão, uma distribuição que abrange várias partes do espaço de estados sem amostras repetidas próximas ao objetivo tende a funcionar melhor; b)~tanto o tamanho do conjunto de amostras quanto a qualidade dos estimadores de custo-para-o-objetivo contribuem para o desempenho da heurística aprendida, sendo os estimadores mais importante; c)~um número suficiente de amostras de boa qualidade resulta em uma função heurística com desempenho comparável às heurísticas tradicionais, embora abordagens independentes de lógica~(por exemplo, sem mutexes) atualmente não sejam tão boas quanto as dependentes de lógica.

Dentre as nossas contribuições, a técnica de melhoria dos estimadores de custo-para-o-objetivo SUI e o limite de regressão adaptativo \meanfx têm os efeitos mais positivos na qualidade da amostragem. Além disso, uma de nossas principais descobertas é que ter menos amostras com estimadores mais precisos é melhor que ter mais amostras com estimadores imprecisos. Também, ter múltiplos \textit{rollouts} de \textit{random walk} -- especialmente quando combinadas com BFS~-- gera amostras de melhor qualidade quando comparadas a usar apenas BFS ou DFS.
