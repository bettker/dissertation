\chapter{Conclusion}
\label{sec:conclusion}

We have presented a study of sample generation and correction strategies for training FNNs to learn heuristic functions for classical planning. We have revised existing approaches to sample generation and proposed a new strategy that uses regression with breadth-first search and random walks, as well as several techniques that improve cost-to-goal estimates. A systematic analysis of small state spaces against ideal baselines seems to indicate that: a) for the samples obtained through regression, a distribution covering diverse portions of the state space without repeated samples close to the goal works best, b) both the sample size and reasonable cost-to-goal estimates contribute to search performance, with the latter being more important, c) enough samples of good quality translate to good search performance that can be compared to logic-based heuristics, although model-free approaches (e.g., without mutexes) are currently not as good as model-based ones.

We confirm the results from \citeyear{OToole/2022} showing that having randomly generated samples up to a limit in the final sample set is always positive; however, this effect is unexplained. Also, when compared to logic-based heuristics, some domains do not have good results with learned heuristics, such as Rovers, that as far as we know, has a low coverage among all NN-based methods. Currently, it is unclear why some domains perform well and others poorly among different learned heuristics. Furthermore, due to the imprecise correlation between validation loss and search quality (regarding both coverage and expanded states), it can be hard to know after training if a learned heuristic will perform well or not when compared to others, so an alternative metric may be needed.

Among our contributions, the $h$-value improvement strategy \hvfc and the adaptive regression limit \meanfx have the most positive effects on sampling quality. The former improves the accuracy of cost-to-goal estimates by analyzing the successors of a state, while the latter avoids overestimates by limiting the maximum regression limit so that we have a more balanced sampling distribution within a reasonable cost-to-goal range. Also, one of our main findings is that having fewer samples with more accurate $h$-values is better than having more samples with inaccurate $h$-values.
Furthermore, having multiple random walk rollouts -- especially when combined with \bfs~-- generates samples with better quality when compared to using only \bfs or \dfs.
