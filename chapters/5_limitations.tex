\chapter{Limitations}
\label{sec:limitations}

This chapter discusses common limitations and problems of methods based on learning heuristics with NNs. Understanding and addressing these limitations are essential for advancing the field and developing more robust and effective learned heuristic functions.

\section{Validation Loss}
\label{sec:validation-loss}

A significant limitation is the unreliability of the validation loss as an indicator of performance during the training. It is not uncommon to observe that two NNs trained with the same configuration have different validation losses, where the network with a larger loss may actually outperform the one with a smaller loss in terms of coverage or number of states expanded during the search.

For example, when training with \hstar-values over states generated with \bfsrw, with one sample seed and $100$ network seeds for each of the small state spaces, $36\,\%$ of the models with the least amount of expanded states had a higher validation loss than other models with more expanded states; if the states do not have \hstar-values, it increases to $49\,\%$. Regarding coverage, in the large state space experiments with the heuristic \hnnrs and $9$ runs ($3$ sample seeds and $3$ network seeds) for each state space, $15\,\%$ of the models with the highest coverage had a higher validation loss than the other models with lower coverage. This happens because the sampling procedure is imperfect -- an NN learns a limited portion of the state space, which varies per sample seed, so even if the validation loss is small, it provides no guarantees of search quality.

This phenomenon challenges model validation methods and clarifies that a lower validation loss does not necessarily translate to a better heuristic function in the search. Consequently, relying solely on validation loss to measure model quality can lead to misleading conclusions and suboptimal decisions about when to stop training or which NN is most effective for the search. Therefore, alternative evaluation metrics and techniques must be explored to more accurately assess the performance and effectiveness of learned heuristic models before the search.

\section{Noisy Training}
\label{sec:noisy-training}

Another limitation to consider is the impact of seed initialization on the training. As noted by other methods that use some form of model validation~\cite{ferber2020neural, shen2020learning, ferber2022neural, otoole2022sampling}, training can be noisy, with multiple runs leading to very different results. A consequence of this is observed in our experiments comparing expanded states, where even a single state that ends up expanded due to an inaccurate heuristic can lead to numerous extra expansions. In contrast, other states can lead the search to a more direct path to the goal~\cite{heusner2017understanding}. Note that this problem is common for all approaches that use \gbfs, but this is further aggravated in NNs that learn from approximated values.

\begin{table}[tb]
    \caption[Expanded states with standard deviations in small state space experiments.]{Expanded states with \gbfs and their standard deviations in small state space experiments using the baseline \hnnbase and the best heuristic \hnnrs.}
    \label{tab:small-stdev}
    \addmargin
    \centering
    \input{tables/small-stdev}
\end{table}

An example is shown in \cref{tab:small-stdev} comparing the mean number of expanded states of the baseline and \hnnrs. We see that standard deviation varies per domain, i.e.,~some domains are noisier than others, and training with better-quality samples typically helps. Regarding coverage in large state spaces, the standard deviation was smaller, as it does not vary at the same rate as expanded states. For example, \hnnrs has a standard deviation of $16\,\%$ in Grid coverage, while the mean standard deviation considering all the other domains is less than $3\,\%$. This limitation highlights the need for careful consideration and systematic analysis of the seeds to ensure reliable and consistent results when training heuristic functions.

\section{State Representation}
\label{sec:limitation-representation}

This work and others~\cite{ferber2020neural, ferber2022neural, otoole2022sampling} use the same STRIPS representation, and the NN is fed with a vector of Boolean values representing the set of facts of a complete state, where each input neuron corresponds to a fact. However, this is inefficient when training over large planning tasks that can have an input size in the order of thousands.

Furthermore, sampling methods via regression generate partial states, which represent a set of complete states, then with the assignment of undefined variables, part of the sampling information is lost. \citet{yu2020learning} use the same STRIPS representation but does not complete the undefined variables, assigning false to all facts corresponding to an undefined variable. Considering undefined states as false is a way around the impossibility of representing undefined values in the Boolean vector; however, it trains the network with a set of states that will never be encountered during the search.

LHFCP~\cite{geissmann2015learning} uses a multivalued \sas vector representation of the state, which aligns with the internal state representation in Fast~Downward. This choice allows the representation of undefined values and increases the speed of the NN by reducing the dimensionality of the input layer. However, the main drawback lies in its inability to capture fine-grained distinctions among facts, as each input neuron corresponds to a set of facts. This limitation could affect the accuracy of the learned heuristic function.
